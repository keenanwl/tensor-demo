services:
  tensorflow-gpu:
    build: .  # Build the Dockerfile in the current directory
    container_name: tensorflow_gpu_container
    volumes:
      - ./nn.py:/app/nn.py           # Mount nn.py into /app/nn.py in the container
      - ./data:/app/data             # Mount the local data directory to /app/data in the container
    working_dir: /app                # Set working directory inside the container
    command: /bin/bash
    stdin_open: true # docker run -i
    tty: true
    ports:
      - "8888:8888"                  # Expose port 8888
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]    # Request GPU support
    environment:
      - NVIDIA_VISIBLE_DEVICES=all   # Make all GPUs visible to the container
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility

# Toolkit for docker host: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html
# docker-compose up --build