services:
  tensorflow-gpu:
    build: .  # Build the Dockerfile in the current directory
    container_name: tensorflow_gpu_container
    volumes:
      - ./train.py:/app/train.py
      - ./data.py:/app/data.py
    working_dir: /app
    command: /bin/bash
    stdin_open: true # docker run -i
    tty: true
    ports:
      - "8888:8888"                  # Expose port 8888
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [gpu]    # Request GPU support
    environment:
      - NVIDIA_VISIBLE_DEVICES=all   # Make all GPUs visible to the container
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility

# Toolkit for docker host: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html
# docker-compose up --build